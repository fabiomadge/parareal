Der Kerngedanke des Parareal Algorithmus ist die Kombination eines groben Lösers \(\mathcal{G}\) mit einem feinen \(\mathcal{F}\) und wurde erstmals in~\cite{Lions:2001} beschrieben. \(\mathcal{F}\) erfüllt die ursprünglich geforderten Anforderungen an die Genauigkeit, während \(\mathcal{G}\) diese nicht erfüllen muss, jedoch eine deutlich kürzere Rechenzeit erfordern soll. Erreicht werden kann dies durch die Verwendung von einer geringeren Anzahl an Zeitschritten, oder einem weniger komplexen Diskretisierungsverfahren. Die Parallelität entsteht durch Gebietszerlegung, also dem Lösen der Gleichung an mehreren Zeitpunkten zur gleichen Zeit. Um dies zu organisieren, wird die Simulationszeit \(\left(t_0, T\right] = \bigcup_{i=0}^{P-1} \left(t_i, t_{i+1}\right]\) in \(P\) Unterintervalle aufgeteilt. Die zur Lösung der Unterintervalle notwendige Rechenzeit sollte möglichst ähnlich sein. Gleichzeitig ist es geschickt, die Schnittstellen \(\left\{t_i \,\middle|\, 1 \leq i \leq P-1\right\}\) jeweils so zu wählen, dass der zu erwartende lokale Fehler möglichst gering ist. Da jedes Unterintervall parallel simuliert werden soll, werden Startwerte benötigt. Zu diesem Zweck wird \(\mathcal{G}\) auf \(\left(t_0, T\right]\) ausgeführt
\begin{displaymath}
    y_{j}^{0} = \mathcal{G}\!\left(y(t_0), t_0, t_{j}\right), \quad j \in \left\{i \,\middle|\, 0 \leq i < P\right\}.
\end{displaymath}
Der grobe Löser wird hier durch eine ternäre Funktion \(\mathcal{G}\!\left(y, t_{A}, t_{\Omega}\right) \approx y(t_\Omega)\) abstrahiert. Das erste Argument enthält den Startwert, das zweite den Startzeitpunkt und das letzte den Endzeitpunkt der Berechnung. Der Wert der Funktion ist eine Approximation für die Lösung der Differentialgleichung zum Zeitpunkt \(t_\Omega\). \(y_j^k\) bezeichnet den Startwert für das Unterintervall \(j\) in der Iteration \(k\). In jeder Iteration wird, ausgehend vom gemeinsamen approximierten Startwert, sowohl \(\mathcal{G}\), als auch \(\mathcal{F}\) ausgeführt. Erlangt wird der Startwert durch die Kombination der Ergebnisse der Löser im zeitlich direkt vorhergehenden Unterintervall
\begin{equation} \label{eq:1}
    y_{j+1}^{k+1} = \mathcal{G}\!\!\left(y_j^{k+1}, t_j, t_{j+1}\right) + \mathcal{F}\!\!\left(y_j^k, t_j, t_{j+1}\right) - \mathcal{G}\!\!\left(y_j^k, t_j, t_{j+1}\right).
\end{equation}
Offensichtlich würde \(y_{j+1}^{k+1} = \mathcal{F}\!\!\left(y_j^{k+1}, t_j, t_{j+1}\right)\) zu einem optimalen Startwert führen, jedoch ließen sich hier keine Gewinne durch Parallelisierung realisieren. Die Idee ist aber dieses Ergebnis möglichst genau vorherzusagen. Dazu wird die Auswirkung des neuen Startwerts auf das Ergebnis von \(\mathcal{F}\) durch die Auswirkung auf \(\mathcal{G}\) abgeschätzt. So kann der systematische Fehler von \(\mathcal{G}\) in eingeschänktem Maß isoliert werden. Diese Vorgehensweise kann anhand von Abbildung~\ref{fig:merge} nachvollzogen werden.
\begin{figure}[ht]
    \centering
        \begin{tikzpicture}[scale=2.2]
            \input{../merge}
        \end{tikzpicture}
    \caption{Entstehung der Korrektur}
    \label{fig:merge}
\end{figure}
Mit jeder Iteration \(i_k\) entspricht ein weiteres Unterintervall genau dem Ergebnis von \(\mathcal{F}\) auf dem Gesamtintervall, da sich der ursprüngliche Anfangswert propagiert. Somit müssen die ersten \(k\) Unterintervalle in \(i_k\) nicht mehr berechnet werden. Dort ist der Fixpunkt lokal bereits erreicht. Dadurch ergeben sich auch die Startwerte für eine neue Iteration
\begin{displaymath}
    y_{j+1}^{k+1} = \mathcal{F}\!\!\left(y_{j}^{k}, t_j, t_{j+1}\right) = \mathcal{F}\!\!\left(y_0, t_0, t_{j+1}\right), \quad j = k.
\end{displaymath}

Das resultierende Verfahren wird als \(\mathcal{P}\!\left(y, t_{A}, t_{\Omega},K,P\right) \approx y(t_\Omega)\) codiert. Über die bekannten Argumente hinaus, werden die Anzahl der Iterationen \(K\) und die Anzahl der Prozesse \(P\) spezifiziert. Wie durch den Buchstaben \(P\) und die Kriterien für die Wahl der Unterintervalle suggeriert, bietet es sich an die Unterintervalle jeweils in einem eigenen Prozess zu berechnen. Der dabei notwendige Ablauf und die Kommunikation zwischen den Prozessen lässt sich mit Hilfe von Abbildung~\ref{fig:sequence} vergegenwärtigen.
\begin{figure}[ht]
    \centering
        \input{../sequence}
    \caption{Auslastung und Kommunikation der Threads}
    \label{fig:sequence}
\end{figure}
Beide Achsen bilden eine Zeit ab. Auf der x-Achse finden sich die Prozesse, also die Unterintervalle; beginnend bei \(t_0\) und aufsteigend angeordnet. Im der Gesamtbetrachtung ergibt sich die Simulationszeit. Die y-Achse zeigt die Realzeit, also die Laufzeit des Programms. Innerhalb der Prozesse werden Paare roter(\(\mathcal{G}\)) und grüner(\(\mathcal{F}\)) Rechtecke wiederholt. Sie unterschieden sich in der Ausdehnung auf der y-Achse, nachdem sie sich in der Laufzeit unterscheiden sollen. Das Paar bildet zusammen eine Iteration. Die Anzahl der Iteration eines Prozesses steigt mit seinem Index, weil sich die exakte Lösungs mit jeder Iteration um ein Unterintervall fortsetzt und somit auch der Anfangswert konstant bleibt. Der Beginn der Berechnungen ist bei den Prozessen jeweils um die Rechenzeit für \(\mathcal{G}\) versetzt, nachdem das Ergebnis des vorherigen Unterintervalls Aufwirkungen auf den Startwert hat. Die erforderliche Kommunikation zwischen den Prozessen wird durch die Pfeile gezeigt. Während der reguläre Pfeil das weitergeben eines direkten Ergebnisses von einem der Löser bedeutet, werden bei dem anderen Pfeil vorher gemäß Gleichung~\ref{eq:1} drei Ergebnisse zusammengeführt. Nachdem ein Prozess eine Iteration beendet hat, blockiert er, bis er einen neuen Startwert vom vorherigen bekommt. Aus der Abbildung ist leicht ersichtlich, dass es nicht sinnvoll ist alle möglichen Iterationen auch durchzuführen. Dies gilt sowohl Laufzeit \(\mathrm{L}(f)\), als auch für die Prozessorzeit. Die Prozessorzeit ist, verglichen mit streng sequenzieller Ausführung bereits nach einer Iteration größer, weil nicht nur \(\mathcal{F}\), sondern auch \(\mathcal{G}\) auf dem Gesamtintervall evaluiert werden muss. Eine optimale Prozessorzeit ist jedoch nicht das Ziel des Algorithmus, sondern eine Optimierung der Laufzeit. Diese ist nach \(P\) Iterationen aber auch schlechter
\begin{align*}
    \mathrm{L}\!\left(\mathcal{F}\!\!\left(y_0, t_0, T\right)\right)
    &\approx P \cdot \mathrm{L}\!\left(\mathcal{F}\!\!\left(y_i, t_i, t_{i+1}\right)\right)\\
    \mathrm{L}\!\left(\mathcal{P}\!\!\left(y_0, t_0, T, K, P\right)\right)
    &\approx K \cdot \mathrm{L}\!\left(\mathcal{F}\!\!\left(y_i, t_i, t_{i+1}\right)\right) + (P-1) (K-1) \mathrm{L}\!\left(\mathcal{G}\!\!\left(y_i, t_i, t_{i+1}\right)\right).
\end{align*}
Dadurch wird klar, dass der Algorithmus nur dann sinnvoll eingesetzt werden kann, wenn \(K \ll P\). Gleichzeitig gilt aber auch, dass in diesem Fall das Ergebnis ein anderes ist.
\subsection*{Experimente}
Um das tatsächliche Verhalten des Algorithmus zu untersuchen, haben wir den Algorithmus in Python implementiert. Für die meisten Analysen wird eine Differentialgleichung deren Lösung durch die logistische Funktion beschrieben wird. Sie kann als Wachstumsmodell unter Berücksichtigung des Ressourcenverbrauchs verwendet werden
\begin{displaymath}
    y'(t) = k \cdot y(t) \cdot (L - y(t)).
\end{displaymath}
Diese Gleichung lässt jedoch eine Schar von Lösungen zu, welche jedoch symbolisch zu berechnen ist. Mit der Randbedingung \(y(0)= \frac{L}{2}\) ist nur noch eine Lösung möglich
\begin{displaymath}
    y(t) = \frac{L}{1+e^{-k L t}}.
\end{displaymath}
Verschiedene numerische Lösungen der Gleichung finden sich oben in Abbildung~\ref{fig:sequence}. Alle sind, unter der Nutzung von 12 Prozessen, mit Parareal gerechnet und unterscheiden sich in der Anzahl der Iterationen. Auffällig sind die Sprungsstellen an den Unterintervallgrenzen und die Tatsache, dass sich mit jeder Iteration das Ergebnis in allen Unterintervallen stärker an das exakte Ergebnis annähert. Der untere Graph zeigt das Gleiche, aber löst die Gleichung für den belasteten Kondensator aus Abbildung~\ref{fig:cap}.
\begin{figure}[ht]
    \centering
        \input{../iter_study_logistic.pgf}
        \input{../iter_study_cap.pgf}
    \caption{Lösung der logistischen Gleichung mit \(L = k = 1\) (oben) und den belasteten Kondensator (unten) nach aufeinanderfolgenden Iterationen.}
    \label{fig:iters_log}
\end{figure}
Der folgendende Teil beschränkt sich auf die Betrachtung der logistischen Gleichung. Um die Entwicklung des Fehlers besser beobachten zu können, kann Abbildung~\ref{fig:iter_error_local} herangezogen werden. Durch die logarithmische Skalierung des lokalen Fehlers werden nun auch verbesserungen in der vierten und fünften Iteration sichtbar. Die Sprungsstellen sind auch hier nach den früheren Iterationen gut sichtbar, verschwinden aber mit der sechsten Iteration, die im Graphen bereits nicht mehr von der letzten Iteration zu unterscheiden ist. Der wird in Bezug auf die exakte Lösung berechnet und wird der Vollständigkeit halber sowohl absolut als auch relativ gezeigt.
\begin{figure}[ht]
    \centering
        \input{../iter_error_local_abs.pgf}
        \input{../iter_error_local_rel.pgf}
    \caption{Lokaler Fehler, absolut (oben) und relativ (unten), der Parareal Lösungen der logistischen Gleichung.}
    \label{fig:iter_error_local}
\end{figure}
Typischerweise liegt die exakte Lösung jedoch nicht vor, wodurch der Vergleich mit einer numerischen Lösung relevant ist. Für Abbildung~\ref{fig:iter_error_local_num} wurde das sequenzielle Ergebnis eines Lösers mit der Genauigkeit von \(\mathcal{F}\) als Vergleich bemüht. Dieser ist natürlich identisch mit der zwölften Iteration. Ab der Zehnten Iteration ist der Fehler nicht mehr darstellbar.\\
\begin{figure}[ht]
    \centering
        \input{../iter_error_local_rel_num.pgf}
    \caption{Lokaler relativer Fehler der Parareal Lösungen der logistischen Gleichung mit der numerischen Lösung als Vergleichswert.}
    \label{fig:iter_error_local_num}
\end{figure}

Bisher hat die Genauigkeit der zugrunde liegenden Diskretisierungsverfahren in den Experimenten keine Rolle gespielt. Untersucht wird nun wie sich eine größere Präzision von \(\mathcal{F}\), bei unverändertem \(\mathcal{G}\), auf dem Gesamtfehler auswirkt. Zur Berechnung wird die 2-Norm verwendet. Verschiedene Iterationszahlen werden in Abbildung~\ref{fig:iter_error} berücksichtigt. Die einzelnen Funktionen haben jeweils zwei Phasen. Eine der starken Verbesserung, wo die Erhöhung der Genauigkeit mit einer starken Verbesserung des Fehlers einhergeht. In der zweiten Phase wird dieser Zusammenhang abgeschwächt. Mit jeder zusätzlichen Iteration verschiebt sich der Übergang in Richtung der größeren Genauigkeit.
\begin{figure}[ht]
    \centering
        \input{../iter_error.pgf}
    \caption{Globaler Fehler bei steigender Präzision von \(\mathcal{F}\).}
    \label{fig:iter_error}
\end{figure}

\subsubsection*{Automatischer Abbruch}
Der erwartbare Wunsch des Nutzers eines Lösers ist es, die Parallelisierung durch eine boolesche Option zu aktivieren. Dies ist jedoch nicht ohne weiteres möglich, nachdem vor der Ausführung des Algorithmus einige Entscheidungen getroffen werden müssen. Dazu zählen die Präzision von \(\mathcal{G}\), die Anzahl der Prozesse und die Anzahl der Iterationen. Vor allem eine feste Anzahl von Iterationen vorzugeben, scheint unpraktikabel. Dies macht ein dynamisches Abbruchkriterium notwendig, welches während der Ausführung den richtigen Zeitpunkt füt den Abbruch findet. Der Vergleich der Abbildungen~\ref{fig:iters_log}, \ref{fig:iter_error_local} und \ref{fig:iter_error_local_num} suggeriert ein erstes Problem. Alle drei lassen verschiedene Iterationsanzahlen als sinnvoll erscheinen. Während der Vergleich mit der exakten Lösung impraktikabel ist, stellt es Offensichtlich das Optimum dar. So liegen die Ergebnisse ab der siebten Iteration zwar näher an der numerischen Lösung, durch den ihr innewohnenden Fehler ist das Ergebnis dadurch effektiv aber nicht besser. Unglücklicherweise liegen jedoch beide Lösungen zur Laufzeit nicht vor.\\

Verfügbar sind jedoch die Größe der Korrekturen beim Zusammenführen der Ergebnisse(Abbildung~\ref{fig:error_corr}), und die Größe der Sprungsstellen am Ende einer Iteration(Abbildung~\ref{fig:error_disc}). Zu sehen sind für einige Genauigkeiten jeweils wie sich die Beobachtete Größe zum globalen Fehler verhält. Die Korrekturen entwickeln sich ungeachtet des Erreichen des Fehlerplateaus konstant weiter und sind folglich kein guter Indikator. Ganz anderes verhält es sich jedoch mit den Sprungsstellen sie scheinen sich ähnlich schnell wie die Fehler zu stabilisieren, dadurch erscheinen sie ein gutes Abbruchkriterium darzustellen.

\begin{figure}[ht]
    \centering
        \input{../error_corr.pgf}
    \caption{Feste Anzahl der Schritte mit verschieden Iterationszahlen; Vergleich von globalem Fehler und größter Korrektur}
    \label{fig:error_corr}
\end{figure}
\begin{figure}[ht]
    \centering
        \input{../error_disc.pgf}
    \caption{Feste Anzahl der Schritte mit verschieden Iterationszahlen; Vergleich von globalem Fehler und größter Sprungstelle}
    \label{fig:error_disc}
\end{figure}

