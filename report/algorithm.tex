Der Kerngedanke des Parareal Algorithmus ist die Kombination eines groben Lösers \(\mathcal{G}\) mit einem feinen \(\mathcal{F}\) und wurde erstmals in~\cite{Lions:2001} beschrieben. \(\mathcal{F}\) erfüllt die ursprünglich geforderten Anforderungen an die Genauigkeit, während \(\mathcal{G}\) diese nicht erfüllen muss, jedoch eine deutlich kürzere Rechenzeit erfordern soll. Erreicht werden kann dies durch die Verwendung von einer geringeren Anzahl an Zeitschritten, oder einem weniger komplexen Diskretisierungsverfahren. Die Parallelität entsteht durch Gebietszerlegung, also dem Lösen der Gleichung an mehreren Zeitpunkten zur gleichen Zeit. Um dies zu organisieren, wird die Simulationszeit \(\left(t_0, T\right] = \bigcup_{i=0}^{P-1} \left(t_i, t_{i+1}\right]\) in \(P\) Unterintervalle aufgeteilt. Die zur Lösung der Unterintervalle notwendige Rechenzeit sollte möglichst ähnlich sein. Gleichzeitig ist es geschickt, die Schnittstellen \(\left\{t_i \,\middle|\, 1 \leq i \leq P-1\right\}\) jeweils so zu wählen, dass der zu erwartende lokale Fehler möglichst gering ist. Da jedes Unterintervall parallel simuliert werden soll, werden Startwerte benötigt. Zu diesem Zweck wird \(\mathcal{G}\) auf \(\left(t_0, T\right]\) ausgeführt
\begin{displaymath}
    y_{j}^{0} = \mathcal{G}\!\left(y(t_0), t_0, t_{j}\right), \quad j \in \left\{i \,\middle|\, 0 \leq i < P\right\}.
\end{displaymath}
Der grobe Löser wird hier durch eine ternäre Funktion \(\mathcal{G}\!\left(y, t_{A}, t_{\Omega}\right) \approx y(t_\Omega)\) abstrahiert. Das erste Argument enthält den Startwert, das zweite den Startzeitpunkt und das letzte den Endzeitpunkt der Berechnung. Der Wert der Funktion ist eine Approximation für die Lösung der Differentialgleichung zum Zeitpunkt \(t_\Omega\). \(y_j^k\) bezeichnet den Startwert für das Unterintervall \(j\) in der Iteration \(k\). In jeder Iteration wird, ausgehend vom gemeinsamen approximierten Startwert, sowohl \(\mathcal{G}\), als auch \(\mathcal{F}\) ausgeführt. Erlangt wird der Startwert durch die Kombination der Ergebnisse der Löser im zeitlich direkt vorhergehenden Unterintervall
\begin{equation} \label{eq:1}
    y_{j+1}^{k+1} = \mathcal{G}\!\!\left(y_j^{k+1}, t_j, t_{j+1}\right) + \mathcal{F}\!\!\left(y_j^k, t_j, t_{j+1}\right) - \mathcal{G}\!\!\left(y_j^k, t_j, t_{j+1}\right).
\end{equation}
Offensichtlich würde \(y_{j+1}^{k+1} = \mathcal{F}\!\!\left(y_j^{k+1}, t_j, t_{j+1}\right)\) zu einem optimalen Startwert führen, jedoch ließen sich hier keine Gewinne durch Parallelisierung realisieren. Die Idee ist aber dieses Ergebnis möglichst genau vorherzusagen. Dazu wird die Auswirkung des neuen Startwerts auf das Ergebnis von \(\mathcal{F}\) durch die Auswirkung auf \(\mathcal{G}\) abgeschätzt. So kann der systematische Fehler von \(\mathcal{G}\) in eingeschänktem Maß isoliert werden. Diese Vorgehensweise kann anhand von Abbildung~\ref{fig:merge} nachvollzogen werden.
\begin{figure}[ht]
    \centering
        \begin{tikzpicture}[scale=2.2]
            \input{../merge}
        \end{tikzpicture}
    \caption{Entstehung der Korrektur}
    \label{fig:merge}
\end{figure}
Mit jeder Iteration \(i_k\) entspricht ein weiteres Unterintervall genau dem Ergebnis von \(\mathcal{F}\) auf dem Gesamtintervall, da sich der ursprüngliche Anfangswert propagiert. Somit müssen die ersten \(k\) Unterintervalle in \(i_k\) nicht mehr berechnet werden. Dort ist der Fixpunkt lokal bereits erreicht. Dadurch ergeben sich auch die Startwerte für eine neue Iteration
\begin{displaymath}
    y_{j+1}^{k+1} = \mathcal{F}\!\!\left(y_{j}^{k}, t_j, t_{j+1}\right) = \mathcal{F}\!\!\left(y_0, t_0, t_{j+1}\right), \quad j = k.
\end{displaymath}

Das resultierende Verfahren wird als \(\mathcal{P}\!\left(y, t_{A}, t_{\Omega},K,P\right) \approx y(t_\Omega)\) codiert. Über die bekannten Argumente hinaus, werden die Anzahl der Iterationen \(K\) und die Anzahl der Prozesse \(P\) spezifiziert. Wie durch den Buchstaben \(P\) und die Kriterien für die Wahl der Unterintervalle suggeriert, bietet es sich an die Unterintervalle jeweils in einem eigenen Prozess zu berechnen. Der dabei notwendige Ablauf und die Kommunikation zwischen den Prozessen lässt sich mit Hilfe von Abbildung~\ref{fig:sequence} vergegenwärtigen.
\begin{figure}[ht]
    \centering
        \input{../sequence}
    \caption{Auslastung und Kommunikation der Threads}
    \label{fig:sequence}
\end{figure}
Beide Achsen bilden eine Zeit ab. Auf der x-Achse finden sich die Prozesse, also die Unterintervalle; beginnend bei \(t_0\) und aufsteigend angeordnet. Im der Gesamtbetrachtung ergibt sich die Simulationszeit. Die y-Achse zeigt die Realzeit, also die Laufzeit des Programms. Innerhalb der Prozesse werden Paare roter(\(\mathcal{G}\)) und grüner(\(\mathcal{F}\)) Rechtecke wiederholt. Sie unterschieden sich in der Ausdehnung auf der y-Achse, nachdem sie sich in der Laufzeit unterscheiden sollen. Das Paar bildet zusammen eine Iteration. Die Anzahl der Iteration eines Prozesses steigt mit seinem Index, weil sich die exakte Lösungs mit jeder Iteration um ein Unterintervall fortsetzt und somit auch der Anfangswert konstant bleibt. Der Beginn der Berechnungen ist bei den Prozessen jeweils um die Rechenzeit für \(\mathcal{G}\) versetzt, nachdem das Ergebnis des vorherigen Unterintervalls Aufwirkungen auf den Startwert hat. Die erforderliche Kommunikation zwischen den Prozessen wird durch die Pfeile gezeigt. Während der reguläre Pfeil das weitergeben eines direkten Ergebnisses von einem der Löser bedeutet, werden bei dem anderen Pfeil vorher gemäß Gleichung~\ref{eq:1} drei Ergebnisse zusammengeführt. Nachdem ein Prozess eine Iteration beendet hat, blockiert er, bis er einen neuen Startwert vom vorherigen bekommt. In der Abbildung ist leicht ersichtlich, dass es nicht sinnvoll ist alle möglichen Iterationen auch durchzuführen. Dies gilt sowohl Laufzeit \(\mathrm{L}(f)\), als auch für die Prozessorzeit. Die Prozessorzeit ist, verglichen mit streng sequenzieller Ausführung bereits nach einer Iteration größer, weil nicht nur \(\mathcal{F}\), sondern auch \(\mathcal{G}\) auf dem Gesamtintervall evaluiert werden muss. Eine optimale Prozessorzeit ist jedoch nicht das Ziel des Algorithmus, sondern eine Optimierung der Laufzeit. Diese ist nach \(P\) Iterationen aber auch schlechter
\begin{align*}
    \mathrm{L}\!\left(\mathcal{F}\!\!\left(y_0, t_0, T\right)\right)
    &\approx P \cdot \mathrm{L}\!\left(\mathcal{F}\!\!\left(y_i, t_i, t_{i+1}\right)\right)\\
    \mathrm{L}\!\left(\mathcal{P}\!\!\left(y_0, t_0, T, K, P\right)\right)
    &\approx K \cdot \mathrm{L}\!\left(\mathcal{F}\!\!\left(y_i, t_i, t_{i+1}\right)\right) + (P-1) (K-1) \mathrm{L}\!\left(\mathcal{G}\!\!\left(y_i, t_i, t_{i+1}\right)\right).
\end{align*}

Abbruch???